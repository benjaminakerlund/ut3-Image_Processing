\section{Introduction to Data Analysis: Data Classification}
\label{sec:data_analysis}

\subsection{Supervised Classification}
\textcolor{blue}{\textbf{Question 1:}}
\textit{Enumerate main supervized classiﬁcation techniques and describe them in few lines.}

%~~~~~~~~~~~~~~ANSWER~~~~~~~~~~~~~~
Supervised Classification is one of the two broad types of digital classification methods used by the majority of image processing systems to analyse remote sensing images. It requires selection of an appropriate classification scheme, and then identification of training areas in the image that best represents each class. In supervised classification, the analyst identifies in the image homogenous representative areas of different land use and land cover types (information classes) of interest. These are called \textit{training areas} or \textit{training samples}. 

The three distinct stages of Supervised Classification are training, classification and output. Training is the identification of a sample of pixels of known classes gathered from reference data, such as field visits, existing maps, reports and aerial photographs. These could be e.g. water, sand, dirt, roads, clouds etc. The key characteristics of selecting training areas are shape, location, number and uniformity.

\cite{garg_remote_2024}


Some typical Supervised Classification techniques are listed and described below:
\begin{enumerate}
    \item \textbf{k-Nearest Neighbours (k-NN):} The most simple classification algorithm where the principle is to find the \textit{k} closest data in the dataset to determine its class. 
    First a distance has to be defined, which is not always easy.

    
    \item \textbf{Maximum Likelihood:} A simple classifier based on the probability distribution.
    It assumes the data follows a known probability distribution (typically normal or Gaussian distr.) for each class.
    ML estimates the probability that a given data point belongs to each possible class and assigns it to the class with the highest likelihood.

    \begin{equation*}
        C^* = \underset{C_i}{\operatorname{argmax}} \, P(C_i \mid o)
    \end{equation*}

    
    \item \textbf{Bayesian Classification:}
    Based on the bayesian rule where given an observation \textit{o}, the \textit{prior} (a priori probability), is described as:
    \begin{equation*}
        P(C_i \mid o) = \frac{P(o \mid C_i) P(C_i)}{P(o)}
    \end{equation*}
    where $P(C_i \mid o)$ is called \textit{posterior} (a posterior probability).

    More text??

    
    \item \textbf{Linear Classification:}
    The most simple classification rule, where the objective is to establish a hyperplane, \textit{HP}, that separates the data into two groups:
    \begin{equation*}
    \begin{split}
        &\mathcal{H} : w_0 + \vec{w} \cdot \vec{x} = 0 \\
        &\text{In a \textit{n}-D space:} \\
        &\mathcal{H} : w_0 + w_1 x_1 + w_2 x_2 + \cdots + w_n x_n = 0
    \end{split}
    \end{equation*}

    Linear Classification is only possible if the data is \textit{linearly separable}. If not, there are infinite solutions
    An example of Linear Classification is the Perceptron Algorithm, which bla bla
    
    
    \item \textbf{Neural Networks:}
    \item \textbf{Decision Trees:}
    \item \textbf{Concept Lattices:}
    \item \textbf{Support Vector Machine}
    \item \textbf{Random Forests:}
    \item \textbf{etc.}
\end{enumerate}



\textcolor{blue}{\textbf{Question 2:}}
\textit{Apply and compare the following algorithms:
\begin{enumerate}
    \item 1-NN (your programme)
    \item Neural Network    
\end{enumerate}
on 'Spain Beach' image or another of your choice}

\begin{enumerate}
    \item 1-NN 

    The first step is to select the data for our classes, which we select at random in predefined areas for 'land', 'beach', 'foam' and 'ocean' classes.
    \begin{figure}[!ht]
        \centering
        \includegraphics[width=0.45\linewidth]{Doc/Graphics/Part4/kNN_training_sets.png}
        \caption{Randomly selected training data}
    \end{figure}

    The output of the algorithm gives us the beach we want to extract
    \begin{figure}[!ht]
        \centering
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Doc/Graphics/Part4/kNN_classified_beach.png}
            \caption{Raw output}
        \end{subfigure} \hfill
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Doc/Graphics/Part4/kNN_masked_beach.png}
            \caption{Smoothened output}
        \end{subfigure}
        \caption{Extracted beach}
        \label{fig:enter-label}
    \end{figure}  
    \FloatBarrier
    
    \item Neural Network
    
    We select two sets of training data, which gives us two classes: 'beach' and 'not beach'. 
    \begin{figure}[!ht]
        \centering
        \begin{subfigure}{0.2\textwidth}
            \centering
            \includegraphics[width=\textwidth, angle=90]{Doc/Graphics/Part4/training_set_beach.png}
            \caption{Beach}
        \end{subfigure}
        \begin{subfigure}{0.4\textwidth}
            \centering
            \includegraphics[width=0.5\textwidth, angle=90]{Doc/Graphics/Part4/training_set_other.png}
            \caption{Not beach}
        \end{subfigure}
        \caption{Training sets}
    \end{figure}
    \FloatBarrier

    The target assigned to beach RGB values is 1 and 0 for the rest. Training the network goes smoothly, and its output results in the following extraction of the beach:
    \begin{figure}[!ht]
        \centering
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Doc/Graphics/Part4/nn_classified_beach.png}
            \caption{Raw output}
        \end{subfigure} \hfill
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Doc/Graphics/Part4/nn_masked_beach.png}
            \caption{Smoothened output}
        \end{subfigure}
        \caption{Extracted beach}
        \label{fig:enter-label}
    \end{figure}
    \FloatBarrier

    \item Comparison

    There are two noticeable differences: speed and noise level. The neural network is much more performant in terms of speed and produces an output with much less noise and better classification (like the river delta in the top right corner).
\end{enumerate}



\textcolor{blue}{\textbf{Question 3:}}
\textit{Search on internet one of the two the following algorithms and apply it to the same image
\begin{enumerate}
    \item SVM
    \item Ramdom Forest
\end{enumerate}
}



% ~~~~~~~~~~~~~~ UNSUPERVISED CLASSIFICATION ~~~~~~~~~~~~~~~~~~
\newpage
\subsection{Unsupervised Classification}
\textcolor{blue}{\textbf{Question 4:}}
\textit{Enumerate main unsupervized classiﬁcation techniques and describe them in few lines.}

Unsupervised Classification in essence reverses the process of supervised classification. It requires less input from the analyst to process the image, as the analyst does not predefined the land use and land cover types. However, the analyst can define the number of output classes required and spectral variance (such as the standard deviation, $\sigma$) within each class. The image is divided into those defined number of classes based entirely on the spectral data and with no prior knowledge of what land use and land cover types may be present in the image. \cite{garg_remote_2024}

\begin{itemize}
    \item \textbf{Clustering} 
    \subitem \textit{K-Means Algorithm}
    \subitem \textit{Kohonen Maps}
    \item \textbf{Regression}
    \item \textbf{Dimension Reduction}
    \subitem \textit{Principal Component Analysis} is the most efficient method for Dimension Reduction. It is based on the variance / covariance matrix, where the main eigenvalues are the most important. Associated eigenvectors describe the reduced state space.
\end{itemize}


\textcolor{blue}{\textbf{Question 5:}}
\textit{Apply the following algorithms with the dedicated objective
\begin{enumerate}
    \item k-means algorithm to deﬁne the four classes automatically and speed-up the classiﬁcation process
    \item Pseudo-Inverse technique to estimate the position of a planet
    \item PCA technique to reduce the size of an image
\end{enumerate}
}

\subsubsection{Principal Component Analysis (PCA)}
Since the images data is three, sometimes four, dimensional, it is of interest to reduce the amount of dimensions to optimize memory usage. This is done with principal component analysis. The core of the method is to find a line or plane of best fit of the data, onto which the data is then projected. This results in less dimensions being needed to store very similar information, which means PCA presents itself as a possible compression algorithm. 

The steps to find the principal axes are as follows:
\begin{enumerate}
    \item Center the data by shifting it by its mean and then calculate the covariance
    \item Determine the eigenvalues and eigenvectors of the covariance matrix
    \item Select the eigenvectors with the largest eigenvalue as the direction vectors of either the plane or the line
\end{enumerate}

Then the data can be compressed by projecting the data onto the plane or line. In order to recover the image after compression, the operation needs to be reversed. For the projection, a simple dot product is enough. In the case of a plane, this looks like
\begin{equation}
    D_\mathrm{proj} = (D_\mathrm{original} - \mathrm{mean} ) \cdot \begin{pmatrix}
        | & | \\
        \vec{v}_1 & \vec{v}_2 \\
        | & | 
    \end{pmatrix}
\end{equation}
where $\vec{v}_1$ and $\vec{v}_2$ are the selected eigenvectors with three components, $D_\mathrm{original}$ is the matrix containing the data of the original image, with dimensions of height~x~width~x~3. The compressed data $D_\mathrm{proj}$ then has dimensions height~x~width~x~2.

To decompress the image, we just need to invert this relation, which yields:
\begin{equation}
    D_\mathrm{original} = D_\mathrm{proj} \cdot \begin{pmatrix}
        | & | \\
        \vec{v}_1 & \vec{v}_2 \\
        | & | 
    \end{pmatrix}^T + \mathrm{mean} 
\end{equation}

We apply the PCA method to the full moon image as a demonstration, and we can see that it is indeed very performant in \autoref{fig:resultsPCA}. The only noticable difference is that the reconstructed image is slightly darker. Since PCA does not touch the number of pixels, the resolution is unaffected by this method. 
\begin{figure}[!ht]
    \centering
    \begin{subfigure}{0.45\textwidth}
    \centering
        \includegraphics[width=\linewidth]{Doc/Graphics/Part4/PCA_im_original.png}
        \caption{Original}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
    \centering
        \includegraphics[width=\linewidth]{Doc/Graphics/Part4/PCA_im_reconstructed.png}
        \caption{Reconstructed}
    \end{subfigure}
    \caption{PCA compression}
    \label{fig:resultsPCA}
\end{figure}
\FloatBarrier

\subsubsection{K-means clustering}

The k-means clustering method enables us to select a number of classes we want, and the algorithm will try its best to cluster the data in this number of classes.

The algorithm is as follows:
\begin{enumerate}
    \item Select the number of classes k
    \item Initialize k centroids from the data points at random
    \item Calculate the distance of each data point to each cluster
    \item Assign each data point to its closest cluster
    \item Compute the new centroid from the cluster set
    \item If the cluster set is empty, select one new centroid at random
    \item Repeat from step 3 until the centroids stop changing.
\end{enumerate}

The advantage of this method is that we can determine an ideal number of classes for our purpose. For example in \autoref{fig:resultsKmeans} we tested multiple values of k on the image \texttt{SpainBeach.jpg} and reconstruct the image so that each pixel is colored based on the centroid of the cluster. We found that to properly extract the beach, at least five or six classes are necessary. In this configuration, the distinction between beach and sea foam is made successfully. Once k goes above six, the image starts to become over-classified, where more details get their own classes, but then classes lose their generality.
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{Doc/Graphics/Part4/kMeans_comparison.png}
    \caption{k-means clustering tests}
    \label{fig:resultsKmeans}
\end{figure}